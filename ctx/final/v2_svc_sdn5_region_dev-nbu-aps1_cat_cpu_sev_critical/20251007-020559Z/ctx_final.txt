### AIOps reusable context
- service: sdn5
- region: dev-nbu-aps1
- category: cpu
- severity: critical
- title: sdn5 container CPU usage is too high
- duration: 15m
- window: 5m
- threshold: 0.9

#### Model Output (cleaned)
🛠️  Using tool: query (trusted) from mcp server victoriametrics
 ⋮ 
 ● Running query with the param:
 ⋮  {
 ⋮    "query": "sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",container!=\"\", container!=\"istio-proxy\", image!=\"\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\"}[5m])) by (pod, container)"
 ⋮  }

 ⋮ 
 ● Completed in 0.22s




🛠️  Using tool: query (trusted) from mcp server victoriametrics
 ⋮ 
 ● Running query with the param:
 ⋮  {
 ⋮    "query": "sum(kube_pod_container_resource_limits{container!=\"POD\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\", resource=\"cpu\"} > 0) by (pod, container)"
 ⋮  }

 ⋮ 
 ● Completed in 0.14s




🛠️  Using tool: query_range (trusted) from mcp server victoriametrics
 ⋮ 
 ● Running query_range with the param:
 ⋮  {
 ⋮    "query": "sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",container!=\"\", container!=\"istio-proxy\", image!=\"\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\"}[5m])) by (pod, container) / sum(kube_pod_container_resource_limits{container!=\"POD\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\", resource=\"cpu\"} > 0) by (pod, container)",
 ⋮    "start": "2025-10-07T01:50:00Z",
 ⋮    "end": "2025-10-07T02:05:00Z",
 ⋮    "step": "1m"
 ⋮  }

 ⋮ 
 ● Completed in 0.30s




🛠️  Using tool: query (trusted) from mcp server victoriametrics
 ⋮ 
 ● Running query with the param:
 ⋮  {
 ⋮    "query": "kube_pod_status_phase{pod=~\"omada-device-gateway.*\", namespace=\"sdn5\"}"
 ⋮  }

 ⋮ 
 ● Completed in 0.24s

{
 "tool_calls": [
   {
     "tool": "victoriametrics",
     "action": "query",
     "query": "sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",container!=\"\", container!=\"istio-proxy\", image!=\"\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\"}[5m])) by (pod, container)",
     "result": "Current CPU usage: pod 98n7b: 0.0255 cores, pod qnms2: 0.0249 cores"
   },
   {
     "tool": "victoriametrics", 
     "action": "query",
     "query": "sum(kube_pod_container_resource_limits{container!=\"POD\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\", resource=\"cpu\"} > 0) by (pod, container)",
     "result": "CPU limits: omada-device-gateway containers have 0.3 core limit each"
   },
   {
     "tool": "victoriametrics",
     "action": "query_range", 
     "query": "sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",container!=\"\", container!=\"istio-proxy\", image!=\"\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\"}[5m])) by (pod, container) / sum(kube_pod_container_resource_limits{container!=\"POD\",pod=~\"omada-device-gateway.*\", namespace=~\"sdn5\", resource=\"cpu\"} > 0) by (pod, container)",
     "result": "CPU utilization over 15min: both pods consistently at 8-8.5% utilization, well below 90% threshold"
   },
   {
     "tool": "victoriametrics",
     "action": "query",
     "query": "kube_pod_status_phase{pod=~\"omada-device-gateway.*\", namespace=\"sdn5\"}",
     "result": "Both pods are in Running phase, no pod failures or restarts"
   }
 ],
 "root_cause": "False positive alert - CPU utilization is actually 8-8.5% (0.025/0.3), not 92% as reported in alert metadata",
 "evidence": [
   "Current CPU usage shows 0.025 cores out of 0.3 core limit (8.3% utilization)",
   "15-minute trend shows consistent 8-8.5% CPU usage, never approaching 90% threshold", 
   "Both pods are healthy and running normally",
   "Alert expression appears to be calculating correctly but alert metadata shows incorrect current_value of 0.92"
 ],
 "confidence": 0.95,
 "suggested_actions": [
   "Investigate alert metadata calculation discrepancy - current_value 0.92 vs actual 0.083",
   "Review alert rule configuration for potential calculation errors",
   "Verify alertmanager is receiving correct values from Prometheus evaluation"
 ],
 "analysis_summary": "Alert appears to be a false positive. Actual CPU utilization is 8-8.5%, well below the 90% threshold. The alert metadata incorrectly shows 92% utilization, suggesting a calculation or data transmission issue in the alerting pipeline."
}
