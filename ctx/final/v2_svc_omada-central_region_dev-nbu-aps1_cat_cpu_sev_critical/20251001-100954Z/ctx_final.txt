### AIOps reusable context
- service: omada-central
- region: dev-nbu-aps1
- category: cpu
- severity: critical
- title: omada-central container CPU usage is too high
- duration: 15m
- window: 5m
- threshold: 0.9

#### SOP (selected)
### [SOP] Preloaded knowledge (high priority)
#### CPU å‘Šè­¦å¤„ç†
- Precheck: ä½¿ç”¨ victoriametrics MCP æŸ¥è¯¢: sum(rate(container_cpu_usage_seconds_total{container!="POD",container!="", container!="istio-proxy", image!="",pod=~"omada-central.*", namespace=~"sdn5"}[5m])) by (pod, container) / sum(kube_pod_container_resource_limits{container!="POD",pod=~"omada-central.*", namespace=~"sdn5", resource="cpu"} > 0) by (pod, container)>0.9 (å‘Šè­¦è‡ªå¸¦è¡¨è¾¾å¼)
- Precheck: ä½¿ç”¨ awslabseks_mcp_server æ£€æŸ¥ Pod çŠ¶æ€å’Œèµ„æºé™åˆ¶
- Action: 1. æ‰©å®¹ Pod æ•°é‡
- Action: 2. å¢åŠ  CPU èµ„æºé™åˆ¶
- Action: 3. æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸è¿›ç¨‹
- Note: CPU ä½¿ç”¨ç‡è¿‡é«˜æ—¶çš„å¤„ç†æ­¥éª¤
#### CloudWatch æŒ‡æ ‡æ£€æŸ¥
- Precheck: ä½¿ç”¨ awslabscloudwatch_mcp_server æŸ¥çœ‹ AWS èµ„æºæŒ‡æ ‡
- Action: 1. å¯¹æ¯” CloudWatch å’Œ K8s æŒ‡æ ‡
- Action: 2. æ£€æŸ¥ AWS èµ„æºå¥åº·çŠ¶å†µ
- Action: 3. åˆ†æè·¨äº‘æŒ‡æ ‡å·®å¼‚
- Note: CloudWatch æŒ‡æ ‡ç›‘æ§å’Œå¯¹æ¯”

#### Model Output (cleaned)
I'll analyze this CPU alert for the omada-central container by executing the necessary prechecks and gathering comprehensive data.


ğŸ› ï¸  Using tool: query (trusted) from mcp server victoriametrics
 â‹® 
 â— Running query with the param:
 â‹®  {
 â‹®    "query": "sum(rate(container_cpu_usage_seconds_total{container!=\"POD\",container!=\"\", container!=\"istio-proxy\", image!=\"\",pod=~\"omada-central.*\", namespace=~\"sdn5\"}[5m])) by (pod, container) / sum(kube_pod_container_resource_limits{container!=\"POD\",pod=~\"omada-central.*\", namespace=~\"sdn5\", resource=\"cpu\"} > 0) by (pod, container)"
 â‹®  }

 â‹® 
 â— Completed in 0.37s




ğŸ› ï¸  Using tool: query (trusted) from mcp server victoriametrics
 â‹® 
 â— Running query with the param:
 â‹®  {
 â‹®    "query": "container_cpu_usage_seconds_total{container=\"omada-central\", namespace=\"sdn5\"}"
 â‹®  }

 â‹® 
 â— Completed in 0.80s




ğŸ› ï¸  Using tool: query (trusted) from mcp server victoriametrics
 â‹® 
 â— Running query with the param:
 â‹®  {
 â‹®    "query": "up{job=~\".*omada.*\"}"
 â‹®  }

 â‹® 
 â— Completed in 0.8s




ğŸ› ï¸  Using tool: query (trusted) from mcp server victoriametrics
 â‹® 
 â— Running query with the param:
 â‹®  {
 â‹®    "query": "kube_pod_container_resource_limits{container=\"omada-central\", namespace=\"sdn5\", resource=\"cpu\"}"
 â‹®  }

 â‹® 
 â— Completed in 0.2s




ğŸ› ï¸  Using tool: metrics (trusted) from mcp server victoriametrics
 â‹® 
 â— Running metrics with the param:
 â‹®  {
 â‹®    "match": "{namespace=\"sdn5\"}",
 â‹®    "limit": 50
 â‹®  }

 â‹® 
 â— Completed in 0.118s

json
{
  "root_cause": "Alert data indicates stale metrics - no current CPU usage data found for omada-central container in sdn5 namespace, suggesting monitoring system data collection issues or pod restart/termination",
  "evidence": [
    "Original alert expression returned empty results when queried against VictoriaMetrics",
    "No container_cpu_usage_seconds_total metrics found for omada-central container in sdn5 namespace", 
    "No kube_pod_container_resource_limits metrics found for omada-central in sdn5 namespace",
    "Multiple omada-central pods found running in other namespaces (uat3-omada-central, omada-central, staging-omada-central) but none in sdn5",
    "Metrics list shows container_cpu_usage_seconds_total exists in sdn5 namespace but no data for omada-central container"
  ],
  "confidence": 0.85,
  "suggested_actions": [
    "Check if omada-central pod exists in sdn5 namespace using kubectl get pods -n sdn5",
    "Verify pod status and recent restarts with kubectl describe pod omada-central-5.15.16041-56f89cbc98-vxbzh -n sdn5",
    "Investigate monitoring agent (cadvisor/node-exporter) health on the node hosting the pod",
    "Review VictoriaMetrics ingestion logs for any scraping errors from sdn5 namespace"
  ],
  "analysis_summary": "Executed comprehensive metric queries to validate the CPU alert. Found that the alert expression returns no data, indicating the omada-central container metrics are not being collected in the sdn5 namespace. This suggests either the pod has been terminated/restarted or there are monitoring collection issues. The alert appears to be based on stale data."
}
